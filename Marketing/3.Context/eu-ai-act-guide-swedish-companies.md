# EU AI ACT - GUIDE FÖR SVENSKA FÖRETAG

**Target**: Svenska företag som vill använda Claude/AI för effektivisering
**Status**: Giltig från 2025-10-02

---

## RISKNIVÅER I EU AI ACT

### Förbjuden AI (Art 5)
- Social scoring
- Manipulativ AI
- Biometrisk massövervakning
- Prediktiv brottsbekämpning (endast profiling)

### Högrisk AI (Art 6, Annex III)
1. Biometrisk identifiering/kategorisering
2. Kritisk infrastruktur (energi, transport)
3. Utbildning (automatiska betyg/antagning)
4. Rekrytering (automatiska beslut om anställning)
5. Grundläggande tjänster (kredit, försäkring, socialförmåner)
6. Brottsbekämpning
7. Migration/gränskontroll
8. Rättsväsende

### Transparenskrav AI (Art 50)
- AI som interagerar med människor
- Innehållsgenerering (text, ljud, video)
- Emotionsigenkänning

### Minimal Risk AI
- Allt annat (produktivitet, analys, innehållsskapande)

---

## CLAUDE FÖR PRODUKTIVITET = MINIMAL RISK

### Varför Inte Högrisk?

**Claude används typiskt för:**
- Textgenerering och redigering
- Kodgenerering och dokumentation
- Analys och sammanfattning
- Research och faktakontroll
- Intern produktivitet

**= INGEN av högrisk-kategorierna i Annex III**

### Undantag Som Skulle Göra Det Högrisk

Om ni använder Claude för:
- Automatiska rekryteringsbeslut → Högrisk
- Kreditbedömning → Högrisk
- Automatiska betyg i utbildning → Högrisk

**Lösning**: Behåll mänsklig kontroll över slutgiltiga beslut

---

## TIDSLINJE 2025-2027

### 2 Februari 2025
**Träder i kraft**: Förbjudna AI-system (Art 5)
**Din action**: Inget (påverkar dig ej)

### 2 Maj 2025
**Deadline**: Codes of practice för GPAI
**Din action**: Inget (gäller Claude/Anthropic)

### 2 Augusti 2025
**Träder i kraft**:
- Governance-strukturer
- GPAI-krav (General Purpose AI)
- Påföljder/sanktioner

**Din action**: Inget (påverkar leverantörer)

### 2 Augusti 2026
**Träder i kraft**: Full AI Act
**Din action**:
- ✅ Transparens vid kundinteraktion med AI
- ✅ Dokumentera AI-användning (frivilligt men smart)
- ✅ GDPR-compliance vid persondata

### 2 Augusti 2027
**Träder i kraft**: Högrisk-krav för large-scale IT
**Din action**: Review om ni utökat användning

---

## HANDLINGSPLAN FÖR SVENSKA BOLAG

### Steg 1: Kartlägg Användning (Nu)
- [ ] Lista alla AI-verktyg ni använder
- [ ] Identifiera användningsområden
- [ ] Klassificera risknivå per användning

### Steg 2: GDPR-Check (Nu)
- [ ] Processas persondata?
- [ ] Laglig grund för behandling?
- [ ] Informerar ni berörda personer?
- [ ] DPA med AI-leverantör?

### Steg 3: Transparens-Policy (Före 2 Aug 2026)
- [ ] Informera kunder om AI-genererat innehåll
- [ ] Märk AI-genererade bilder/videos
- [ ] Tydliggör när AI används i kundinteraktion

### Steg 4: Intern Dokumentation (Frivilligt men rekommenderat)
- [ ] AI-användningspolicy
- [ ] Syfte med varje AI-system
- [ ] Ansvarig person/avdelning
- [ ] Riskbedömning

### Steg 5: Framtidssäkring (Löpande)
- [ ] Följ EU AI Office guidelines (från 2025)
- [ ] Uppdatera policies årligen
- [ ] Review vid nya användningsområden

---

## DOKUMENTATIONSMALLAR

### Mall 1: AI-Användningspolicy

```markdown
## AI-ANVÄNDNINGSPOLICY [FÖRETAGSNAMN]

**Datum**: [YYYY-MM-DD]
**Ansvarig**: [Namn, titel]

### Syfte
Vi använder AI för att effektivisera [specifika områden].

### AI-Verktyg i Användning
- **Claude (Anthropic)**: Textgenerering, kodassistans, dokumentation
- [Andra verktyg]

### Användningsområden
1. **Intern produktivitet**: Sammanfattningar, dokumentation
2. **Kundkommunikation**: [Specificera]
3. **Utveckling**: Kodgenerering, code reviews

### Transparens
- Kunder informeras när AI används i kundinteraktion
- AI-genererat innehåll märks som sådant
- Mänsklig review av allt kundfacing material

### GDPR-Compliance
- Persondata behandlas enligt GDPR
- DPA finns med Anthropic
- Känslig data anonymiseras innan AI-användning

### Review
Policy reviewas årligen, nästa gång: [Datum]
```

### Mall 2: Transparensmeddelande Kunder

```markdown
**För kundkommunikation:**
"Detta innehåll har genererats med hjälp av AI och granskats av [roll]."

**För chatbots/assistenter:**
"Du interagerar nu med en AI-assistent. Vid specifika frågor kommer du att
kopplas till en medarbetare."

**För AI-genererade bilder:**
[Watermark eller metadata]: "AI-generated image"
```

### Mall 3: Riskbedömning Ny AI-Användning

```markdown
## RISKBEDÖMNING AI-SYSTEM

**System**: [Namn på AI-verktyg]
**Datum**: [YYYY-MM-DD]

### 1. Användningsområde
[Beskriv]

### 2. Riskkategori (enligt EU AI Act)
- [ ] Förbjuden
- [ ] Högrisk
- [ ] Transparenskrav
- [X] Minimal risk

**Motivering**: [Förklara varför]

### 3. Påverkar Beslut Om Personer?
- [ ] Ja → Kräver mänsklig övervakning
- [X] Nej

### 4. GDPR-Impact
- Processas persondata? [Ja/Nej]
- Laglig grund: [Specificera]
- Informationsplikt: [Uppfylld/Ej relevant]

### 5. Slutsats
- [X] Godkänd för användning
- [ ] Kräver ytterligare åtgärder: [Lista]
- [ ] Ej godkänd

**Godkänd av**: [Namn, titel, datum]
```

---

## VANLIGA FRÅGOR

**Q: Måste vi registrera Claude-användning?**
A: Nej, endast högrisk-system kräver registrering i EU-databasen.

**Q: Kan vi använda Claude för kundmail?**
A: Ja, men informera att AI använts om det inte är uppenbart.

**Q: Vad händer om vi bryter mot AI Act?**
A: Böter upp till 35M EUR eller 7% av omsättning (högrisk/förbjuden AI).
   Minimal risk = inga sanktioner.

**Q: Måste vi ha DPA med Anthropic?**
A: Ja, om ni behandlar persondata (GDPR-krav, inte AI Act).

**Q: Gäller detta även open source AI?**
A: Nej, Art 2(12): Open source AI undantaget såvida det inte är högrisk
   eller förbjudet.

**Q: Vad är "mänsklig övervakning"?**
A: En människa granskar och kan ändra AI-genererat innehåll innan beslut/publicering.

---

## KÄLLOR & REFERENSER

- **EU AI Act**: Regulation (EU) 2024/1689
- **Anthropic Trust Center**: trust.anthropic.com
- **EU AI Office**: digital-strategy.ec.europa.eu/ai-office
- **IMY (Sverige)**: datainspektionen.se (GDPR-vägledning)

---

**Senast uppdaterad**: 2025-10-02
**Nästa review**: 2026-02-01
